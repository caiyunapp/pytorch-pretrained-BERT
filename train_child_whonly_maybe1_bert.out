06/09/2019 16:46:49 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file /nas/pretrain-bert/pretrain-pytorch/bert-base-uncased-vocab.txt
06/09/2019 16:46:49 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file /nas/pretrain-bert/pretrain-pytorch/bert-base-uncased-vocab.txt
06/09/2019 16:46:53 - INFO - run_child_finetuning -   device: cuda n_gpu: 1
06/09/2019 16:46:53 - INFO - pytorch_pretrained_bert.modeling -   loading archive file /nas/pretrain-bert/pretrain-pytorch/bert-base-uncased
06/09/2019 16:46:53 - INFO - pytorch_pretrained_bert.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

06/09/2019 16:46:56 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
06/09/2019 16:46:58 - INFO - run_child_finetuning -   Epoch 0
06/09/2019 16:46:58 - INFO - run_child_finetuning -   Evaluating on train set...
06/09/2019 16:46:58 - INFO - run_child_finetuning -   Evaluating on valid set...
Epoch:   0%|          | 0/3 [00:00<?, ?it/s]06/09/2019 16:47:18 - INFO - run_child_finetuning -   Epoch 1
06/09/2019 16:47:18 - INFO - run_child_finetuning -   Evaluating on train set...
06/09/2019 16:47:33 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:47:33 - INFO - run_child_finetuning -     eval_accuracy = 1.0
06/09/2019 16:47:33 - INFO - run_child_finetuning -     eval_loss = 4.1338801383972165e-05
06/09/2019 16:47:34 - INFO - run_child_finetuning -   Evaluating on valid set...
06/09/2019 16:47:49 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:47:49 - INFO - run_child_finetuning -     eval_accuracy = 1.0
06/09/2019 16:47:49 - INFO - run_child_finetuning -     eval_loss = 4.583547512690226e-05
Epoch:  33%|███▎      | 1/3 [00:50<01:41, 50.93s/it]06/09/2019 16:48:09 - INFO - run_child_finetuning -   Epoch 2
06/09/2019 16:48:09 - INFO - run_child_finetuning -   Evaluating on train set...
06/09/2019 16:48:24 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:48:24 - INFO - run_child_finetuning -     eval_accuracy = 1.0
06/09/2019 16:48:24 - INFO - run_child_finetuning -     eval_loss = 7.879237333933512e-06
06/09/2019 16:48:24 - INFO - run_child_finetuning -   Evaluating on valid set...
06/09/2019 16:48:40 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:48:40 - INFO - run_child_finetuning -     eval_accuracy = 1.0
06/09/2019 16:48:40 - INFO - run_child_finetuning -     eval_loss = 1.040796438852946e-05
Epoch:  67%|██████▋   | 2/3 [01:41<00:50, 50.88s/it]06/09/2019 16:49:00 - INFO - run_child_finetuning -   Epoch 3
06/09/2019 16:49:00 - INFO - run_child_finetuning -   Evaluating on train set...
06/09/2019 16:49:15 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:49:15 - INFO - run_child_finetuning -     eval_accuracy = 1.0
06/09/2019 16:49:15 - INFO - run_child_finetuning -     eval_loss = 6.37670358022054e-06
06/09/2019 16:49:15 - INFO - run_child_finetuning -   Evaluating on valid set...
06/09/2019 16:49:30 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:49:30 - INFO - run_child_finetuning -     eval_accuracy = 1.0
06/09/2019 16:49:30 - INFO - run_child_finetuning -     eval_loss = 8.151431878407796e-06
Epoch: 100%|██████████| 3/3 [02:32<00:00, 50.81s/it]
/home/qsj/miniconda3/bin/python: Error while finding module specification for 'train_child.py' (AttributeError: module 'train_child' has no attribute '__path__')
Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.
Warning:  apex was installed without --cuda_ext. Fused syncbn kernels will be unavailable.  Python fallbacks will be used instead.
Warning:  apex was installed without --cuda_ext.  FusedAdam will be unavailable.
Warning:  apex was installed without --cuda_ext.  FusedLayerNorm will be unavailable.
Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
Namespace(dev_percent=0.5, do_eval=True, do_lower_case=True, do_train=True, eval_batch_size=128, gradient_accumulation_steps=1, learning_rate=3e-05, max_seq_length=128, no_cuda=False, num_train_epochs=3.0, seed=42, train_batch_size=32, warmup_proportion=0.1)
num_sent = 7680 -> 5760
num_train_steps = 360
global_step 0, lr = 0.000000
