06/09/2019 16:43:11 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file /nas/pretrain-bert/pretrain-pytorch/bert-base-uncased-vocab.txt
06/09/2019 16:43:11 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file /nas/pretrain-bert/pretrain-pytorch/bert-base-uncased-vocab.txt
06/09/2019 16:43:13 - INFO - run_child_finetuning -   device: cuda n_gpu: 1
06/09/2019 16:43:13 - INFO - pytorch_pretrained_bert.modeling -   loading archive file /nas/pretrain-bert/pretrain-pytorch/bert-base-uncased
06/09/2019 16:43:13 - INFO - pytorch_pretrained_bert.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

06/09/2019 16:43:16 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
06/09/2019 16:43:18 - INFO - run_child_finetuning -   Epoch 0
06/09/2019 16:43:18 - INFO - run_child_finetuning -   Evaluating on train set...
06/09/2019 16:43:18 - INFO - run_child_finetuning -   Evaluating on valid set...
Epoch:   0%|          | 0/3 [00:00<?, ?it/s]06/09/2019 16:43:28 - INFO - run_child_finetuning -   Epoch 1
06/09/2019 16:43:28 - INFO - run_child_finetuning -   Evaluating on train set...
06/09/2019 16:43:36 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:43:36 - INFO - run_child_finetuning -     eval_accuracy = 0.9973958333333334
06/09/2019 16:43:36 - INFO - run_child_finetuning -     eval_loss = 0.006977510452270508
06/09/2019 16:43:36 - INFO - run_child_finetuning -   Evaluating on valid set...
06/09/2019 16:43:43 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:43:43 - INFO - run_child_finetuning -     eval_accuracy = 0.9947916666666666
06/09/2019 16:43:43 - INFO - run_child_finetuning -     eval_loss = 0.013682023187478383
Epoch:  33%|███▎      | 1/3 [00:25<00:50, 25.31s/it]06/09/2019 16:43:53 - INFO - run_child_finetuning -   Epoch 2
06/09/2019 16:43:53 - INFO - run_child_finetuning -   Evaluating on train set...
06/09/2019 16:44:01 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:44:01 - INFO - run_child_finetuning -     eval_accuracy = 1.0
06/09/2019 16:44:01 - INFO - run_child_finetuning -     eval_loss = 1.3010700543721517e-05
06/09/2019 16:44:01 - INFO - run_child_finetuning -   Evaluating on valid set...
06/09/2019 16:44:09 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:44:09 - INFO - run_child_finetuning -     eval_accuracy = 1.0
06/09/2019 16:44:09 - INFO - run_child_finetuning -     eval_loss = 1.2679894765218098e-05
Epoch:  67%|██████▋   | 2/3 [00:50<00:25, 25.30s/it]06/09/2019 16:44:19 - INFO - run_child_finetuning -   Epoch 3
06/09/2019 16:44:19 - INFO - run_child_finetuning -   Evaluating on train set...
06/09/2019 16:44:26 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:44:26 - INFO - run_child_finetuning -     eval_accuracy = 1.0
06/09/2019 16:44:26 - INFO - run_child_finetuning -     eval_loss = 9.955962498982747e-06
06/09/2019 16:44:26 - INFO - run_child_finetuning -   Evaluating on valid set...
06/09/2019 16:44:34 - INFO - run_child_finetuning -   ***** Eval results *****
06/09/2019 16:44:34 - INFO - run_child_finetuning -     eval_accuracy = 1.0
06/09/2019 16:44:34 - INFO - run_child_finetuning -     eval_loss = 9.877483050028483e-06
Epoch: 100%|██████████| 3/3 [01:15<00:00, 25.33s/it]
/home/qsj/miniconda3/bin/python: Error while finding module specification for 'train_child.py' (AttributeError: module 'train_child' has no attribute '__path__')
Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.
Warning:  apex was installed without --cuda_ext. Fused syncbn kernels will be unavailable.  Python fallbacks will be used instead.
Warning:  apex was installed without --cuda_ext.  FusedAdam will be unavailable.
Warning:  apex was installed without --cuda_ext.  FusedLayerNorm will be unavailable.
Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
Namespace(dev_percent=0.5, do_eval=True, do_lower_case=True, do_train=True, eval_batch_size=128, gradient_accumulation_steps=1, learning_rate=3e-05, max_seq_length=128, no_cuda=False, num_train_epochs=3.0, seed=42, train_batch_size=32, warmup_proportion=0.1)
num_sent = 3840 -> 3840
num_train_steps = 180
global_step 0, lr = 0.000000
